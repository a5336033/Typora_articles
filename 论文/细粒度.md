# WS-DAN

## 摘要

提出了弱监督数据增强网络，具体而言，对于每个训练图像，首先通过弱监督学习生成注意映射来表示对象的区分部分。然后在注意图的引导下对图像进行增强，包括attention cropping和attention dropping。提出WS-DAN在两方面提高了分类精度。第一阶段，提取更多具有鉴别性的局部特征，可以更好的识别图像。第二阶段，注意力区域提供对目标的精确定位，保证了模型更近地观察目标，从而进一步提高性能。普通细粒度分类数据集上的表现表明，优于现有方法。

## 引入

以往的工作通常通过随机数据增强对训练数据进行预处理。eg：随机图像裁剪可以生成平移和缩放不同的图像，提高深度模型的鲁棒性。裁剪区域是随机采样的，其中很大部分含有背景噪声。可能会降低训练效率，影响提取特征的质量。

为了增强数据增强的效率，模型需要了解目标对象的空间信息。

细粒度识别是将从属级别分类到一个基本级别的类别下。比如鸟的种类，汽车型号，飞机类型。

FGVC挑战：

1. 内部类高方差。属于同一类别的物体通常表现出明显不同的姿势和视角。
2. 低类间差异。属于不同类别的物体除了一些小的差异外可能非常相似。eg：鸟的颜色通常可以判断它的类别。
3. 有限的训练数据。通常标记细粒度的类别需要专业知识和大量的注释时间。

由于这些原因，仅依靠最先进的粗粒度卷积神经网络（CNN），如：VGG、ResNet和Inception，很难获得准确的分类结果。

正如一些工作指出的，FGVC的关键步骤是在多个目标部位提取更具鉴别性的局部特征。对象的各个部分很难定义，不同对象的部分也不同，为这些物体的各个部分贴上标签需要额外的人力成本。

**通过弱监督学习仅通过图像级注释来定位鉴别对象的部分。**

**没有提出兴趣边界框区域，而是通过卷积生成的注意映射来表示**对象的部分或视觉模式。

还提出双线性注意池化和注意正则化损失对注意生成过程进行弱监督。与其他的局部定位模型相比，更容易地定位对象的大量零件，从而达到更好的性能。

在获得各部分位置后，我们提出了注意力引导的数据增强，以有效地增强训练数据，解决上述类内方差高、类间方差低的问题。

不同的细粒度类别，除了少数差异外，对象通常非常相似。注意力裁剪可以通过裁剪和调整局部区域的大小来区分它们，从而提取出更具辨别力的局部特征。对于同样的细粒度类别，如果模型只关注对象的少数部分，当这些部分由于姿态和视点的差异而被遮挡时，很可能会产生错误的预测。因此，从物体的不同部分提取局部特征是至关重要的。

attention dropping：随机地从图像中擦除对象区域的一部分，鼓励网络从其他物体的部分提取辨别特征。因此，通过注意引导的数据增强，模型可以在对象的多个部分提取更多的鉴别特征，这意味着对象可以更好地被看到。注意力引导数据增强的另一个好处，可以更好的定位目标，使我们的模型更近距离地观察物体，并改进预测。对于每个测试图像，对象类别将从粗到细预测。

模型首先预测目标的区域和分类的粗阶段概率，然后，对目标区域进行放大，并预测细化概率。

贡献：

1. 提出弱监督注意力学习去生成注意力图来表示辨别对象各部位的空间分布。并提取连续的局部特征去解决细粒度分类问题。
2. 在注意力maps的基础上，提出了注意导向的数据增强方法，包括注意裁剪和注意下降。注意力随机裁剪，调整注意部分的大小以增强局部特征的表征。注意下降随机删除图像中的一个注意区域，鼓励模型从多个区分部分中提取特征。
3. 利用注意力图对目标进行定位，并对目标进行放大，进一步提高分类精度。

## 相关工作

细粒度分类：已经开发了各种方法来区分不同的细粒度类别。为解决大规模的图像分类问题，提出了卷积神经网络。

![image-20221021154439991](E:/OneDrive/Typora文章/assets/细粒度/image-20221021154439991.png)

这些基础模型只能达到中等的性能，没有特殊设计，很难关注到物体各部分的细微差别。

为关注局部特征，许多方法依赖于部件的位置或属性的注释。

Part R-CNN扩展R-CNN以检测对象并在几何先验下对其部分进行本地化，然后从姿势规范化表示中预测细粒度类别。

Deep LAC，将对齐和分类误差反向传播到定位。还提出了一个阀连接功能来连接定位和分类模块。

为降低传统的位置标注成本，只需要图像级标注的方法得到了更多的关注。Lin等人提出双线性池化和改进的双线性池化，其中两个特征在每个位置使用外积组合，考虑了它们的成对相互作用。MPN-COV通过矩阵方阵改进了二阶池化，实现了最先进的 精度。

ST-CNN通过学习适当的几何变换并对图像进行对齐，从而达到高分类性能。该方法还可以同时定位多个物体的部分。

RA-CNN循环预测一个注意区域的位置并提取相应的特征，该方法只关注一个局部的部分，因此它们结合三个尺度特征，即三个对象的部分，来预测最终的类别。

为了同时生成多个注意力位置，Zheng等人提出MA-CNN，它同时定位多个身体部位。提出了通道分组损失，通过聚类生成多个部件。然而，目标的部分数量是有限的 ，可能会限制准确性。

本文提出**将注意力与特征层相结合的双线性注意池**，其注意区域的数量更容易增加，并提高分类精度。如下图。

![image-20221021160703145](E:/OneDrive/Typora文章/assets/细粒度/image-20221021160703145.png)

引入了度量学习，Sun等人提出的将MAMC loss，将积极的特征拉向锚点。将消极的特征推开。

Dubey等人提出了PC，将两两混淆损失与交叉熵损失相结合，学习具有更大泛化能力的特征，从而防止过拟合。

本文的模型，提出了注意正则化损失，对目标的注意区域和相应的局部特征进行正则化，提高了目标部分的同一性和分类精度。

### 数据增强

数据增强方法着重于图像的**空间增强**。在之前图像裁剪和图像下降等已经被提出，并被证明能有效地提高深度模型的鲁棒性。

Maxdrop旨在删除最大激活的特征，以鼓励网络考虑不太突出的特征。

缺点：maxdrop只能删除每张图像的一个鉴别区域，这限制了它们的性能。Cutout和Hide-and-Seek通过随机屏蔽训练图像中的许多正方形区域，提高cnn的鲁棒性。然而，很多被擦除的区域都是不想关的背景，或者整个目标被擦除，尤其是小物体。

随机数据增强的效率低，产生大量不受控制的噪声数据。为克服这些问题，提出了一些考虑数据分布的方法，这些方法比随机数据增强更有效。Cubuk等人提出了AutoAugmentation来创建数据增强策略的搜索空间。自动设计特定的策略，以获得最先进的验证精度的目标数据集。Peng等人提出了对抗数据增强，联合优化数据增强和深度模型。设计增强网络在线生成硬数据，提高深度模型的鲁棒性。然而，特定于数据的增强比随机增强复杂的多。我们的注意力引导数据增强更简单，可以生成部分级增强来提高性能。

### 面向局部的弱监督学习

弱监督学习是一个综合性的术语，涵盖了各种试图通过弱监督学习构建预测模型的研究。仅通过图像级监督来准确定位物体或其部件是非常具有挑战性的。

早期工作通过全局平均池化生成特定的定位图。激活区域可以反映对象的位置。然而，采用软最大交叉熵损失训练通常会导致模型关注最具鉴别性的位置，其输出边界框只覆盖了对象的一部分。

为了定位整个对象，Singh等对输入图像的patch进行随机隐藏，迫使网络去寻找其他有区别的部分。然而，由于缺乏高层指导，这一过程是低效的。

Zhang等人提出**对敌互补学习**，通过训练两个对敌互补分类器来发现整个对象，该分类器可以定位不同对象的各个部分，并发现属于同一对象的互补区域，。然后，在它们的实现中只有两个互补的区域，限制了准确性。

注意力引导数据增强鼓励模型关注多个对象的部分，提取更多的鉴别特征，并在对象局部化方面取得显著的性能。

![image-20221021185941890](E:/OneDrive/Typora文章/assets/细粒度/image-20221021185941890.png)

### 方法

弱监督注意学习、注意引导数据扩充、目标定位与细化。



![image-20221021191250610](E:/OneDrive/Typora文章/assets/细粒度/image-20221021191250610.png)

训练过程

![image-20221021191336632](E:/OneDrive/Typora文章/assets/细粒度/image-20221021191336632.png)

测试过程

### 弱监督注意学习

#### 空间表示

首先预测目标的局部区域。在训练和测试期间，目标的位置注释（例如边界框或关键点）是不可用的。该方法采用弱监督学习方法，仅通过对象的类别标注来预测目标的位置分布。

CNN提取图像I的特征，并将F∈R（H×W×N）表示为特征图，物体各部分的分布用注意力图来表示。它是由F变换获得的，

![image-20221022125916991](E:/OneDrive/Typora文章/assets/细粒度/image-20221022125916991.png)

f(·)卷积函数，Ak表示对象的一个部分，如鸟的头部、飞机机翼，M是注意力图的数量。第3节中，将使用注意力图来增强训练数据。

由于注意力映射在FGVC任务中更灵活，更容易端到端训练，因此我们提出了用注意力映射来划分对象部位的区域，而不是SS或RPN

#### 双线性注意力集中

用注意力映射A表示对象部分后，受双线性池的启发，聚合了来自两个流网络层的特征表示。提出了双线性注意池（BAP）从这些部分提取特征。

在元素上将特征映射F乘以每个注意力映射Ak，以生成M部分特征映射Fk。

![image-20221022131956702](E:/OneDrive/Typora文章/assets/细粒度/image-20221022131956702.png)



![image-20221022132346342](E:/OneDrive/Typora文章/assets/细粒度/image-20221022132346342.png)表示两个张量相乘。然后，通过附加特征提取函数g(·)进一步提取判别局部特征，如全局平均池(GAP)、全局最大池(GMP)或卷积，以获得第k个注意特征fk∈R1×N。![image-20221022132456582](E:/OneDrive/Typora文章/assets/细粒度/image-20221022132456582.png)

对象的特征用part特征矩阵表示，

![image-20221022132604397](https://raw.githubusercontent.com/a5336033/note/main/img%5C202210221326081.png)





惩罚属于同一物体局部的特征差异，



#### attention drpping

注意正则化损失监督每个映射Ak，表示相同的第K个对象的部分，而不同的注意映射可能关注相似对象的部分。

为鼓励注意力图代表多个辨别对象的部分，提出了注意力裁剪。具体而言，通过将大于阈值θd∈[0,1]的元素A * k(i, j)设置为0，将其他元素设置为1，从而获得注意力下降掩模Dk。

![image-20221022134436892](https://raw.githubusercontent.com/a5336033/note/main/img%5C202210221345020.png)

通过Dk遮蔽图像I去除第k部分区域，增强后的图像如图所示。

![image-20221022134834071](E:/OneDrive/Typora文章/assets/细粒度/image-20221022134834071.png)

去掉了第K个目标的部分，鼓励网络提出其他可识别的部分，这意味着目标也能被更好地看到，提高了分类的鲁棒性和定位的准确性。

#### 对象定位和细化

注意力引导的数据增强也有助于先前弱监督的注意学习过程，可以更准确地预测目标的位置。

测试过程中，模型输出原始图像的粗阶段分类结果和相应的注意图，可以对目标的整个区域进行预测，并通过相同的网络模型将其放大预测细粒度结果。目标映射Am表示对象的位置。

![image-20221022141554670](E:/OneDrive/Typora文章/assets/细粒度/image-20221022141554670.png)

最后的分类结果由粗粒度预测和细粒度预测求平均值。粗到细预测的具体过程如下：

![image-20221022141709896](E:/OneDrive/Typora文章/assets/细粒度/image-20221022141709896.png)





## 总结

弱监督学习和数据增强相结合。wsl为da提供目标的空间分布，da鼓励wsl的注意学习过程，相互促进，促进模型提取来自多个局部区域的更具辨别性的图像特征。

